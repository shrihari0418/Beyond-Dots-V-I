{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zGU4HvaA7hQw"},"outputs":[],"source":["import cv2\n","import numpy as np"]},{"cell_type":"code","source":["!pip install gtts\n","!pip install ipython\n","!pip install pydub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JW1hBBXW8Ua_","executionInfo":{"status":"ok","timestamp":1710407977075,"user_tz":-330,"elapsed":23863,"user":{"displayName":"Punit Marda","userId":"11696270732081547456"}},"outputId":"378ac5ef-c95d-4c62-9d10-7fb236e6f02e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gtts\n","  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n","Installing collected packages: gtts\n","Successfully installed gtts-2.5.1\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n","Collecting jedi>=0.16 (from ipython)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n","Installing collected packages: jedi\n","Successfully installed jedi-0.19.1\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","\n","def enhance_shadows(image):\n","    # Convert the image to LAB color space\n","    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n","\n","    # Split the LAB image into channels\n","    l_channel, a_channel, b_channel = cv2.split(lab_image)\n","\n","    # Apply CLAHE to the L channel (lightness)\n","    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n","    enhanced_l_channel = clahe.apply(l_channel)\n","\n","    # Merge the enhanced L channel with the original A and B channels\n","    enhanced_lab_image = cv2.merge([enhanced_l_channel, a_channel, b_channel])\n","\n","    # Convert the enhanced LAB image back to BGR color space\n","    enhanced_image = cv2.cvtColor(enhanced_lab_image, cv2.COLOR_LAB2BGR)\n","\n","    return enhanced_image\n","\n","def detect_braille_character(matrix):\n","    # Define the Braille alphabet mapping\n","    braille_alphabet = {\n","        (1, 0, 0, 0, 0, 0): 'A',\n","        (1, 0, 1, 0, 0, 0): 'B',\n","        (1, 1, 0, 0, 0, 0): 'C',\n","        (1, 1, 0, 1, 0, 0): 'D',\n","        (1, 0, 0, 1, 0, 0): 'E',\n","        (1, 1, 1, 0, 0, 0): 'F',\n","        (1, 1, 1, 1, 0, 0): 'G',\n","        (1, 0, 1, 1, 0, 0): 'H',\n","        (0, 1, 1, 0, 0, 0): 'I',\n","        (0, 1, 1, 1, 0, 0): 'J',\n","        (1, 0, 0, 0, 1, 0): 'K',\n","        (1, 0, 1, 0, 1, 0): 'L',\n","        (1, 1, 0, 0, 1, 0): 'M',\n","        (1, 1, 0, 1, 1, 0): 'N',\n","        (1, 0, 0, 1, 1, 0): 'O',\n","        (1, 1, 1, 0, 1, 0): 'P',\n","        (1, 1, 1, 1, 1, 0): 'Q',\n","        (1, 0, 1, 1, 1, 0): 'R',\n","        (0, 1, 1, 0, 1, 0): 'S',\n","        (0, 1, 1, 1, 1, 0): 'T',\n","        (1, 0, 0, 0, 1, 1): 'U',\n","        (1, 0, 1, 0, 1, 1): 'V',\n","        (0, 1, 1, 1, 0, 1): 'W',\n","        (1, 1, 0, 0, 1, 1): 'X',\n","        (1, 1, 0, 1, 1, 1): 'Y',\n","        (1, 0, 0, 1, 1, 1): 'Z',\n","        # Add more mappings as needed\n","    }\n","\n","    # Define the Braille number mapping\n","    braille_numbers = {\n","        (0, 0, 1, 1, 1, 0): '0',\n","        (1, 0, 0, 0, 0, 0): '1',\n","        (1, 0, 1, 0, 0, 0): '2',\n","        (1, 1, 0, 0, 0, 0): '3',\n","        (1, 0, 0, 1, 0, 0): '4',\n","        (1, 1, 0, 1, 0, 0): '5',\n","        (1, 1, 0, 1, 1, 0): '6',\n","        (1, 1, 0, 0, 1, 0): '7',\n","        (0, 1, 0, 1, 0, 0): '8',\n","        (0, 1, 0, 1, 1, 0): '9',\n","    }\n","\n","    # Convert the matrix to a tuple of 1s and 0s\n","    dot_pattern = tuple(matrix.flatten().tolist())\n","\n","    # Check if the dot pattern is in the Braille alphabet mapping\n","    if dot_pattern in braille_alphabet:\n","        return braille_alphabet[dot_pattern], 'letter'\n","    elif dot_pattern in braille_numbers:\n","        return braille_numbers[dot_pattern], 'number'\n","    else:\n","        return '?', 'unknown'\n","\n","# Load the image using OpenCV\n","image_path = '/content/braille_F.png'  # Replace with the actual path\n","image = cv2.imread(image_path)\n","matrices = [\n","    np.array([[1, 0], [0, 0], [0, 0]]),\n","    np.array([[1, 0], [1, 0], [0, 0]]),\n","    np.array([[1, 1], [0, 0], [0, 0]]),\n","    np.array([[1, 1], [0, 1], [0, 0]]),\n","    np.array([[1, 0], [0, 1], [0, 0]]),\n","    np.array([[1, 1], [1, 0], [0, 0]]),\n","    np.array([[1, 1], [1, 1], [0, 0]]),\n","    np.array([[1, 0], [1, 1], [0, 0]]),\n","    np.array([[0, 1], [1, 0], [0, 0]]),\n","    np.array([[0, 1], [1, 1], [0, 0]]),\n","    np.array([[1, 0], [0, 0], [1, 0]]),\n","    np.array([[1, 0], [1, 0], [1, 0]]),\n","    np.array([[1, 1], [0, 0], [1, 0]]),\n","    np.array([[1, 1], [0, 1], [1, 0]]),\n","    np.array([[1, 0], [0, 1], [1, 0]]),\n","    np.array([[1, 1], [1, 0], [1, 0]]),\n","    np.array([[1, 1], [1, 1], [1, 0]]),\n","    np.array([[1, 0], [1, 1], [1, 0]]),\n","    np.array([[0, 1], [1, 0], [1, 0]]),\n","    np.array([[0, 1], [1, 1], [1, 0]]),\n","    np.array([[1, 0], [0, 0], [1, 1]]),\n","    np.array([[1, 0], [1, 0], [1, 1]]),\n","    np.array([[0, 1], [1, 1], [0, 1]]),\n","    np.array([[1, 1], [0, 0], [1, 1]]),\n","    np.array([[1, 1], [0, 1], [1, 1]]),\n","    np.array([[0, 0], [1, 1], [1, 0]]),\n","    np.array([[1, 0], [0, 0], [0, 0]]),\n","    np.array([[1, 0], [1, 0], [0, 0]]),\n","    np.array([[1, 1], [0, 0], [0, 0]]),\n","    np.array([[1, 0], [0, 1], [0, 0]]),\n","    np.array([[1, 1], [0, 1], [0, 0]]),\n","    np.array([[1, 1], [0, 1], [1, 0]]),\n","    np.array([[1, 1], [0, 0], [1, 0]]),\n","    np.array([[0, 1], [0, 1], [0, 0]]),\n","    np.array([[0, 1], [0, 1], [1, 0]]),\n","\n","\n","]\n","\n","# Enhance shadows of the image\n","enhanced_image = enhance_shadows(image)\n","\n","# Convert the enhanced image to HSV color space\n","hsv_image = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2HSV)\n","\n","# Extract the saturation channel\n","saturation_channel = hsv_image[:, :, 1]\n","\n","# Define a saturation threshold for black and white conversion\n","saturation_threshold = 18\n","\n","# Create a binary mask based on saturation\n","saturation_mask = (saturation_channel <= saturation_threshold).astype(np.uint8) * 255\n","\n","# Apply the saturation mask to the original image\n","result_image = cv2.bitwise_and(enhanced_image, enhanced_image, mask=saturation_mask)\n","\n","# Convert the result to grayscale\n","result_gray = cv2.cvtColor(result_image, cv2.COLOR_BGR2GRAY)\n","\n","# Threshold the grayscale image to obtain a binary representation\n","_, binary_image = cv2.threshold(result_gray, 150, 255, cv2.THRESH_BINARY)\n","\n","# Resize the image to a 3x2 matrix\n","resized_image = cv2.resize(binary_image, (2, 3))\n","\n","# Invert the colors (assuming black dots on a white background)\n","resized_image = cv2.bitwise_not(resized_image)\n","\n","# Convert the image matrix to a binary representation\n","matrix = (resized_image > 128).astype(int)\n","\n","# Detect the Braille letter or number\n","braille_character, character_type = detect_braille_character(matrix)\n","print('Detected Braille Character:', braille_character)\n","print('Character Type:', character_type)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjGjyPktipmd","executionInfo":{"status":"ok","timestamp":1710408047274,"user_tz":-330,"elapsed":518,"user":{"displayName":"Punit Marda","userId":"11696270732081547456"}},"outputId":"d7c8437e-2d1b-464b-c22f-0b34bd393be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected Braille Character: F\n","Character Type: letter\n"]}]},{"cell_type":"code","source":["# Import the required libraries\n","from IPython.display import Audio\n","from gtts import gTTS\n","\n","# Define the text you want to convert to speech\n","text = braille_character\n","\n","# Choose the language of the speech (Hindi)\n","language = 'hi'\n","\n","# Convert text to speech\n","myobj = gTTS(text=text, lang=language, slow=False)\n","\n","# Save the audio file (optional)\n","myobj.save(\"speech.mp3\")\n","\n","# Play the audio directly in Colab\n","Audio(\"speech.mp3\", autoplay=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"kVH6EhpLSOpv","executionInfo":{"status":"ok","timestamp":1710407575962,"user_tz":-330,"elapsed":837,"user":{"displayName":"SHRIHARI'S CRAY STUDUO","userId":"16600864490289232618"}},"outputId":"7308c53a-36ec-401f-aa1b-0e57ef6cb09f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.Audio object>"],"text/html":["\n","                <audio  controls=\"controls\" autoplay=\"autoplay\">\n","                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["code for sentence"],"metadata":{"id":"6v46uWu-SA0n"}},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","\n","def enhance_shadows(image):\n","    # Convert the image to LAB color space\n","    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n","\n","    # Split the LAB image into channels\n","    l_channel, a_channel, b_channel = cv2.split(lab_image)\n","\n","    # Apply CLAHE to the L channel (lightness)\n","    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n","    enhanced_l_channel = clahe.apply(l_channel)\n","\n","    # Merge the enhanced L channel with the original A and B channels\n","    enhanced_lab_image = cv2.merge([enhanced_l_channel, a_channel, b_channel])\n","\n","    # Convert the enhanced LAB image back to BGR color space\n","    enhanced_image = cv2.cvtColor(enhanced_lab_image, cv2.COLOR_LAB2BGR)\n","\n","    return enhanced_image\n","\n","def detect_braille_character(matrix):\n","    # Define the Braille alphabet mapping\n","    braille_alphabet = {\n","        (1, 0, 0, 0, 0, 0): 'A',\n","        (1, 0, 1, 0, 0, 0): 'B',\n","        (1, 1, 0, 0, 0, 0): 'C',\n","        (1, 1, 0, 1, 0, 0): 'D',\n","        (1, 0, 0, 1, 0, 0): 'E',\n","        (1, 1, 0, 1, 0, 0): 'F',\n","        (1, 1, 0, 1, 1, 0): 'G',\n","        (1, 1, 0, 0, 1, 0): 'H',\n","        (0, 1, 0, 1, 0, 0): 'I',\n","        (0, 1, 0, 1, 1, 0): 'J',\n","        (1, 0, 1, 0, 0, 0): 'K',\n","        (1, 1, 1, 0, 0, 0): 'L',\n","        (1 ,1 ,0 ,0 ,1 ,0): 'M',\n","        (1, 0, 1, 1, 1, 0): 'R',\n","        (1, 0, 1, 0, 1, 0): 'O',\n","        (1, 1, 1, 0, 1, 0): 'P',\n","        (1, 1, 1, 1, 1, 0): 'Q',\n","        (0, 1, 1, 1, 0, 0): 'S',\n","        (0, 1, 1, 1, 1, 0): 'T',\n","        (1, 0, 1, 0, 0, 1): 'U',\n","        (1, 0, 1, 0, 1, 1): 'V',\n","        (0, 1, 1, 1, 0, 1): 'W',\n","        (1, 1, 0, 0, 1, 1): 'X',\n","        (1, 1, 0, 1, 1, 1): 'Y',\n","        (1, 0, 0, 1, 1, 1): 'Z',\n","        # Add more mappings as needed\n","    }\n","\n","    # Define the Braille number mapping\n","    braille_numbers = {\n","        (0, 0, 1, 1, 1, 0): '0',\n","        (1, 0, 0, 0, 0, 0): '1',\n","        (1, 0, 1, 0, 0, 0): '2',\n","        (1, 1, 0, 0, 0, 0): '3',\n","        (1, 0, 0, 1, 0, 0): '4',\n","        (1, 1, 0, 1, 0, 0): '5',\n","        (1, 1, 0, 1, 1, 0): '6',\n","        (1, 1, 0, 0, 1, 0): '7',\n","        (0, 1, 0, 1, 0, 0): '8',\n","        (0, 1, 0, 1, 1, 0): '9',\n","    }\n","\n","    # Convert the matrix to a tuple of 1s and 0s\n","    dot_pattern = tuple(matrix.flatten().tolist())\n","\n","    # Check if the dot pattern is in the Braille alphabet mapping\n","    if dot_pattern in braille_alphabet:\n","        return braille_alphabet[dot_pattern], 'letter'\n","    elif dot_pattern in braille_numbers:\n","        return braille_numbers[dot_pattern], 'number'\n","    else:\n","        return '?', 'unknown'\n","\n","##############################################\n","\n","def process_braille_image(image_path):\n","    # Load the image\n","    image = cv2.imread(image_path)\n","\n","    # Preprocess the image\n","    enhanced_image = enhance_shadows(image)\n","    hsv_image = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2HSV)\n","    saturation_channel = hsv_image[:, :, 1]\n","    saturation_mask = (saturation_channel <= 18).astype(np.uint8) * 255\n","    result_image = cv2.bitwise_and(enhanced_image, enhanced_image, mask=saturation_mask)\n","    result_gray = cv2.cvtColor(result_image, cv2.COLOR_BGR2GRAY)\n","    _, binary_image = cv2.threshold(result_gray, 150, 255, cv2.THRESH_BINARY)\n","\n","    # Segment individual characters\n","    characters = segment_braille_characters(binary_image)\n","\n","    sentence = \"\"\n","    for character in characters:\n","        # Resize the character image to 3x2\n","        resized_character = cv2.resize(character, (2, 3))\n","\n","        # Invert colors (assuming black dots on white background)\n","        resized_character = cv2.bitwise_not(resized_character)\n","\n","        # Convert the image matrix to a binary representation\n","        matrix = (resized_character > 128).astype(int)\n","\n","        # Detect the Braille letter or number\n","        braille_char, char_type = detect_braille_character(matrix)\n","        sentence += braille_char\n","\n","    return sentence\n","\n","def segment_braille_characters(binary_image):\n","\n","   # Apply morphological operations (optional)\n","    kernel = np.ones((3, 3), np.uint8)  # Adjust kernel size as needed\n","    eroded_image = cv2.erode(binary_image, kernel, iterations=1)  # Reduce noise\n","    print(eroded_image)\n","\n","    # Find contours\n","    contours, _ = cv2.findContours(eroded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    # Filter contours based on area, aspect ratio, and solidity\n","    filtered_contours = []\n","    for cnt in contours:\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        aspect_ratio = float(w) / h\n","        solidity = cv2.contourArea(cnt) / cv2.contourArea(cv2.convexHull(cnt))  # Measure shape compactness\n","        if 15 < cv2.contourArea(cnt) < 100 and 0.7 < aspect_ratio < 1.3 and solidity > 0.8:  # Adjust thresholds as needed\n","            filtered_contours.append(cnt)\n","\n","    # Extract ROI (Region of Interest) for each character\n","    segmented_characters = []\n","    for cnt in filtered_contours:\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        roi = binary_image[y:y+h, x:x+w]\n","        segmented_characters.append(roi)\n","\n","    return segmented_characters\n","\n","# Example usage\n","image_path = '/content/love.png'  # Replace with the actual path\n","#image = cv2.imread(image_path)\n","sentence = process_braille_image(image_path)\n","print('Braille sentence:', sentence)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uxmm0s2OR_gQ","executionInfo":{"status":"ok","timestamp":1710393204700,"user_tz":-330,"elapsed":406,"user":{"displayName":"SHRIHARI'S CRAY STUDUO","userId":"16600864490289232618"}},"outputId":"18126e7d-589c-443a-9a0a-71081e77f9cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[255 255 255 ... 255 255 255]\n"," [255 255 255 ... 255 255 255]\n"," [255 255 255 ... 255 255 255]\n"," ...\n"," [255 255 255 ... 255 255 255]\n"," [255 255 255 ... 255 255 255]\n"," [255 255 255 ... 255 255 255]]\n","Braille sentence: \n"]}]},{"cell_type":"code","source":["def process_braille_image(image_path):\n","    # Load the image\n","    image = cv2.imread(image_path)\n","\n","    # Preprocess the image\n","    enhanced_image = enhance_shadows(image)\n","    hsv_image = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2HSV)\n","    saturation_channel = hsv_image[:, :, 1]\n","    saturation_mask = (saturation_channel <= 18).astype(np.uint8) * 255\n","    result_image = cv2.bitwise_and(enhanced_image, enhanced_image, mask=saturation_mask)\n","    result_gray = cv2.cvtColor(result_image, cv2.COLOR_BGR2GRAY)\n","    _, binary_image = cv2.threshold(result_gray, 150, 255, cv2.THRESH_BINARY)\n","\n","    # Segment individual characters\n","    characters = segment_braille_characters(binary_image)\n","\n","    sentence = \"\"\n","    for character in characters:\n","        # Resize the character image to 3x2\n","        resized_character = cv2.resize(character, (2, 3))\n","\n","        # Invert colors (assuming black dots on white background)\n","        resized_character = cv2.bitwise_not(resized_character)\n","\n","        # Convert the image matrix to a binary representation\n","        matrix = (resized_character > 128).astype(int)\n","\n","        # Detect the Braille letter or number\n","        braille_char, char_type = detect_braille_character(matrix)\n","        sentence += braille_char\n","\n","    return sentence\n","\n","def segment_braille_characters(binary_image):\n","\n","    # Find contours\n","    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    # Filter contours based on area and aspect ratio\n","    filtered_contours = []\n","    for cnt in contours:\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        aspect_ratio = float(w) / h\n","        if 15 < cv2.contourArea(cnt) < 100 and 0.7 < aspect_ratio < 1.3:  # Adjust thresholds as needed\n","            filtered_contours.append(cnt)\n","\n","    # Extract ROI (Region of Interest) for each character\n","    segmented_characters = []\n","    for cnt in filtered_contours:\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        roi = binary_image[y:y+h, x:x+w]\n","        segmented_characters.append(roi)\n","\n","    return segmented_characters\n","\n","# Example usage\n","image_path = '/contents/ig.png'  # Replace with the actual path\n","sentence = process_braille_image(image_path)\n","print('Braille sentence:', sentence)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"d64p8o51RkE6","executionInfo":{"status":"error","timestamp":1710391899006,"user_tz":-330,"elapsed":410,"user":{"displayName":"SHRIHARI'S CRAY STUDUO","userId":"16600864490289232618"}},"outputId":"ef1d9807-d9ec-4488-b37f-71a6f294589c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"error","evalue":"OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ad41015fcb01>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/contents/ig.png'\u001b[0m  \u001b[0;31m# Replace with the actual path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_braille_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Braille sentence:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ad41015fcb01>\u001b[0m in \u001b[0;36mprocess_braille_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Preprocess the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0menhanced_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance_shadows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mhsv_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menhanced_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msaturation_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhsv_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-988378fb3840>\u001b[0m in \u001b[0;36menhance_shadows\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0menhance_shadows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Convert the image to LAB color space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlab_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2LAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Split the LAB image into channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"cell_type":"code","source":["# Import the required libraries\n","from IPython.display import Audio\n","from gtts import gTTS\n","\n","# Define the text you want to convert to speech\n","text = braille_character\n","\n","# Choose the language of the speech (Hindi)\n","language = 'hi'\n","\n","# Convert text to speech\n","myobj = gTTS(text=text, lang=language, slow=False)\n","\n","# Save the audio file (optional)\n","myobj.save(\"speech.mp3\")\n","\n","# Play the audio directly in Colab\n","Audio(\"speech.mp3\", autoplay=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"0oq-cNzwz_Fn","executionInfo":{"status":"ok","timestamp":1710390788207,"user_tz":-330,"elapsed":712,"user":{"displayName":"SHRIHARI'S CRAY STUDUO","userId":"16600864490289232618"}},"outputId":"08e3a33f-1dd9-4212-898f-99205fc6fc72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.Audio object>"],"text/html":["\n","                <audio  controls=\"controls\" autoplay=\"autoplay\">\n","                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"dM-ztCSz0EAG"},"execution_count":null,"outputs":[]}]}